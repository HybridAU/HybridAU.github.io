<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="./theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="shortcut icon" type="image/png" href="./favicon.png" />
  <link rel="stylesheet" type="text/css" href="./theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="./theme/css/pygments.css">
  <!--
  This is almost certainly the wrong way to do this but it's the only way
  I can find to load the fonts in a subdirectory
  -->
    <link rel="stylesheet" type="text/css" href="./theme/css/load-fonts.css">
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Michael Van Delft">
  <meta name="description" content="Posts and writings by Michael Van Delft">


<meta name="keywords" content="Backups, Disaster Recovery, Amazon, Cloud">

  <title>Backup to S3 and restore to EC2 &ndash; Exotic Security</title>

</head>

<body>
  <aside>
    <div id="user_meta">
      <a href=".">
        <img src="/images/gavitar_140.png" alt="logo">
      </a>
      <h2><a href=".">Michael Van Delft</a></h2>
      <p>Exotic Security</p>
      <ul>
        <li><a href="./pages/about.html">About</a></li>
        <li><a href="/tags.html">Tags</a></li>
      </ul>
    </div>
  </aside>

  <main>
    <header>
      <p>
      <a href=".">Index</a> &brvbar; <a href="./archives.html">Archives</a>
      </p>
    </header>

<article>
  <div class="article_title">
    <h3><a href="./backup-to-s3-and-restore-to-ec2.html">Backup to S3 and restore to EC2</a></h3>
  </div>
  <div class="article_text">
    <p>There is an old saying that "there are two types of sysadmins, those that do make backups and those that will make backups". Hopefully there are not too many of the second group. But backing up the data is only part of the picture, you also need to think about how you are going to restore it for a full disaster recovery (DR) plan.</p>
<p>Unfortunately a DR solution can be costly, our previous strategy we bought a server with enough hard disk space, RAM and CPU grunt to hold our off site backups and to spin up all our VMs to replicate our production environment in the event of a disaster. I can't remember the exact price of the server but it was in the tens of thousands of dollars plus the ongoing cost of hosting it in a data center somewhere. It cost almost as much as our production environment and sat there not doing much<sup id="fnref:not-doing-much"><a class="footnote-ref" href="#fn:not-doing-much">1</a></sup> for five years before being decommissioned.</p>
<p>Now I'm not saying it was a complete waste of money, had there been a disaster it would have been worth every cent. But for a small to medium sized organisation that's a huge upfront cost that I think can be avoided. This is where being able to purchase compute power <em>on demand</em> and <em>separate from storage</em> absolutely shines. It turns a huge capital expenditure into a small operational expenditure that is only paid in the event of a disaster (or during DR testing).</p>
<p>So when I was asked to do up the specs for our new DR server I though about using a cloud<sup id="fnref:cloud"><a class="footnote-ref" href="#fn:cloud">2</a></sup> hosting provider who could give us storage and only pay for CPU and RAM when we needed it. We looked at a few hosting providers, including <a href="http://aws.amazon.com/">Amazon</a>, <a href="https://azure.microsoft.com/en-us/">Azure</a>, <a href="https://www.binarylane.com.au/">binary lane</a> and some local providers who are not really "Cloud" vendors but would provide us storage and has spare physical machines as needed. I think any of them could have done it but in the end we settled on Amazon.</p>
<p>It saved us a huge amount of money and worked very well. So how did we do it?</p>
<p><img alt="Disaster Recovery Process" src="./images/Disaster-Recovery-Process.png"></p>
<p>In this diagram we don't backup the Terminal Server, instead we treat it like a desktop machine and rebuild it.</p>
<h2>Implementation</h2>
<h3>Local Backup</h3>
<p>We use <a href="http://www.veeam.com/vm-backup-recovery-replication-software.html">Veeam Backup and Replication</a><sup id="fnref:veeam"><a class="footnote-ref" href="#fn:veeam">3</a></sup> to backup our servers to a local backup server. Nothing fancy about that except a few small caveats; disks need to be either VHD or VMDK to work with <a href="http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/ApiReference-cmd-ImportVolume.html">ec2-import-volumne</a> and not VHDX, VDI, etc.. also hard drives can't be over 1TB each as the import can't handle larger files. Lastly it's best to have a separate jobs for each server so if you have 5 servers, setup 5 seperate backup jobs (or even more, if you wanted you could setup one job for each disk, so a single server with 3 VHDs would have 3 backup jobs). This will create separate backup files and allow you to parallelize your restore process.</p>
<h3>Offsite Storage</h3>
<p>Then we push a copy of our backups into S3, we used <a href="http://www.veeam.com/backup-cloud-edition-licensing-faq.html">Veeam Cloud Backup</a> to push our backups off, but that got discontinued so now we are using <a href="http://www.cloudberrylab.com/enterprise-cloud-backup-software.aspx">CloudBerry Backup</a><sup id="fnref:cloudberry"><a class="footnote-ref" href="#fn:cloudberry">4</a></sup> which as far as I can tell is exactly the same product but rebadged<sup id="fnref:rebadged"><a class="footnote-ref" href="#fn:rebadged">5</a></sup>.</p>
<h3>Restore Procedures</h3>
<p>So far it's all been fairly standard but the restore is where it gets interesting. First we setup one EC2 and installed all the required software for a restore onto it; Veeam, CloudBerry Backup, and the <a href="http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/ec2-cli-get-set-up.html">AWS Commandline tools</a> setup with an API key. We setup ours with a fairly small hard drive (EBS) in our case we set it to 40GB.</p>
<p>Once it's been setup and ready to do a restore we can shut it down and make a snapshot to create an <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">Amazon Machine Image</a> (AMI). This way if we want to restore 5 servers, we can spin up 5 DR servers to start the recovery and we can attach larger hard drives to each as a scratch disk to use for the restore (you will want about twice the size of the disks you are restoring).</p>
<p>First you pull the Veeam files (.vbm, .vbk and .vib's) out of S3 onto the scratch disk with CloudBerry Backup and then import that into Veeam Backup and Replication to convert it back to a .vhd file.</p>
<p>Once you have a .vhd file you can import them into AWS, you can import bootable disks with <a href="http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/ApiReference-cmd-ImportInstance.html">ec2-import-instance</a> will create a new EC2 and you can import volumes with <a href="http://docs.aws.amazon.com/AWSEC2/latest/CommandLineReference/ApiReference-cmd-ImportVolume.html">ec2-import-volumne</a> which will create a EBS (virtual hard disk) that can be attached to</p>
<div class="highlight"><pre><span></span><code>ec2-import-instance D:\Database_Severver_C.vhd -t t2.medium -f vhd -a x86_64 -b import-ebs-volumes --subnet subnet-1234567a -o <span class="nv">%AWS_ACCESS_KEY%</span> -w <span class="nv">%AWS_SECRET_KEY%</span> -p Windows -z ap-southeast-2a --region ap-southeast-2
</code></pre></div>

<div class="highlight"><pre><span></span><code>ec2-import-volume D:\Database_Severver_D.vhd -f vhd -z ap-southeast-2a -o <span class="nv">%AWS_ACCESS_KEY%</span> -w <span class="nv">%AWS_SECRET_KEY%</span> -b import-ebs-volumes --region ap-southeast-2
</code></pre></div>

<p>All in all I'm fairly happy with how it all works. We do new full backups every 3 months (run on a Friday with each server is out of step to give us the weekend to upload the new full backup) and then daily incrementals. All backups are kept in S3 and then migrated to glacier after 12 months. We only pay for the storage in S3 which is relatively cheap (It costs less per month than our data center hosting for the old server did with no upfront cost) and during our DR tests everything has come back up fairly well.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:not-doing-much">
<p>Other than the occasional DR test which where less frequent than they should have been I suspect it never peaked over 1% CPU and 5% RAM usage.&#160;<a class="footnote-backref" href="#fnref:not-doing-much" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:cloud">
<p>I usually try to avoid the word "Cloud" because I find it an ambiguous sales term but sometimes it's hard.&#160;<a class="footnote-backref" href="#fnref:cloud" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:veeam">
<p>I'm sure it would work with other backup software, although we tried <a href="http://www.storagecraft.com.au/">ShadowProtect</a> which is good but didn't work because of the way it modifies .vhd files on restore to do their "Hardware independent restore".&#160;<a class="footnote-backref" href="#fnref:veeam" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:cloudberry">
<p>Veeam gave us a free license for CloudBerry Backup when they discontinued their version.&#160;<a class="footnote-backref" href="#fnref:cloudberry" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:rebadged">
<p>I suspect it may have been the otherway around, Veeam Cloud Bacup was just CloudBerry Backup that had been rebadged with the Veeam logo.&#160;<a class="footnote-backref" href="#fnref:rebadged" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>
  <div class="article_meta">
      <p>Posted on: <abbr title="2015-10-01 07:00:00+08:00" >Thu 01 October 2015</abbr></p>
    <p>Category: <a href="./category/posts.html">Posts</a>
 &ndash; Tags:
      <a href="./tag/backups.html">Backups</a>,      <a href="./tag/disaster-recovery.html">Disaster Recovery</a>,      <a href="./tag/amazon.html">Amazon</a>,      <a href="./tag/cloud.html">Cloud</a>    </p>
  </div>


</article>


    <div id="ending_message">
      <p>
        <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">
            <img alt="Creative Commons License" src="./theme/images/cc-by-88x31.png" />
        </a>
        <br />Content on this site is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
        <br />Built using <a href="http://getpelican.com">Pelican</a>.
              Based on a theme by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack">github</a>.
      </p>
    </div>
  </main>
</body>
</html>